{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG System Demo\n",
    "\n",
    "This notebook demonstrates the capabilities of the Multimodal RAG System for Document Intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model: sentence-transformers/all-mpnet-base-v2\n",
      "Embedding Dimension: 768\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_config, get_logger\n",
    "\n",
    "config = get_config()\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "print(f\"Embedding Model: {config.embedding.model_name}\")\n",
    "print(f\"Embedding Dimension: {config.embedding.embedding_dim}\")\n",
    "print(f\"Device: {config.embedding.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:01:13 | \u001b[32mINFO\u001b[0m | TextChunker | Created 1 chunks\n",
      "Created 1 chunks:\n",
      "\n",
      "[Chunk 1] (502 chars)\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables computers \n",
      "to learn from data ...\n"
     ]
    }
   ],
   "source": [
    "from src.preprocessing import TextChunker\n",
    "\n",
    "# Initialize chunker (note: chunk_overlap, not overlap)\n",
    "chunker = TextChunker(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "sample_text = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence that enables computers \n",
    "to learn from data without being explicitly programmed. Deep learning, a more \n",
    "advanced form of machine learning, uses neural networks with multiple layers to \n",
    "model complex patterns in data.\n",
    "\n",
    "Natural Language Processing (NLP) is a field that combines linguistics and machine \n",
    "learning to enable computers to understand human language. Applications include \n",
    "sentiment analysis, machine translation, and question answering.\n",
    "\"\"\"\n",
    "\n",
    "chunks = chunker.chunk(sample_text)\n",
    "print(f\"Created {len(chunks)} chunks:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n[Chunk {i+1}] ({len(chunk.text)} chars)\")\n",
    "    print(chunk.text[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:01:13 | \u001b[32mINFO\u001b[0m | CustomEmbedder | Loading embedding model: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Study\\Code\\Multimodal RAG System for Document Intelligence\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|█████████| 199/199 [00:00<00:00, 684.95it/s, Materializing param=pooler.dense.weight]\n",
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:01:46 | \u001b[32mINFO\u001b[0m | CustomEmbedder | Model loaded: sentence-transformers/all-mpnet-base-v2 (dim=768, device=cpu)\n",
      "Embeddings shape: (3, 768)\n",
      "\n",
      "Similarity Matrix:\n",
      "[[ 1.     0.534 -0.012]\n",
      " [ 0.534  1.    -0.003]\n",
      " [-0.012 -0.003  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "from src.embeddings import CustomEmbedder\n",
    "\n",
    "# Initialize embedder (use CPU for demo)\n",
    "embedder = CustomEmbedder(device=\"cpu\")\n",
    "\n",
    "# Sample texts\n",
    "texts = [\n",
    "    \"Machine learning enables computers to learn from data.\",\n",
    "    \"Deep learning uses neural networks with many layers.\",\n",
    "    \"The weather is sunny today.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embedder.encode(texts)\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Calculate similarity\n",
    "similarities = embedder.similarity(embeddings, embeddings)\n",
    "print(\"\\nSimilarity Matrix:\")\n",
    "print(np.round(similarities, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vector Search with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:01:47 | \u001b[32mINFO\u001b[0m | FAISSVectorStore | Initialized FAISS flat index\n",
      "2026-02-07 16:01:47 | \u001b[32mINFO\u001b[0m | FAISSVectorStore | Added 3 documents to FAISS\n",
      "Documents in store: 3\n"
     ]
    }
   ],
   "source": [
    "from src.retrieval.vector_db import FAISSVectorStore, Document\n",
    "\n",
    "# Create documents\n",
    "documents = [\n",
    "    Document(id=\"1\", text=\"Machine learning is a type of AI.\", embedding=embeddings[0]),\n",
    "    Document(id=\"2\", text=\"Deep learning uses neural networks.\", embedding=embeddings[1]),\n",
    "    Document(id=\"3\", text=\"The weather is nice.\", embedding=embeddings[2]),\n",
    "]\n",
    "\n",
    "# Initialize FAISS store\n",
    "store = FAISSVectorStore(embedding_dim=embeddings.shape[1], index_type=\"flat\")\n",
    "store.add_documents(documents)\n",
    "\n",
    "print(f\"Documents in store: {store.count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Metrics:\n",
      "  Precision@1: 1.0000\n",
      "  Recall@1: 0.5000\n",
      "  NDCG@1: 1.0000\n",
      "  Hit Rate@1: 1.0000\n",
      "  Precision@3: 0.3333\n",
      "  Recall@3: 0.5000\n",
      "  NDCG@3: 0.6131\n",
      "  Hit Rate@3: 1.0000\n",
      "  Precision@5: 0.4000\n",
      "  Recall@5: 1.0000\n",
      "  NDCG@5: 0.8772\n",
      "  Hit Rate@5: 1.0000\n",
      "  MRR: 1.0000\n",
      "\n",
      "Generation Metrics:\n",
      "  ROUGE1: 0.7500\n",
      "  ROUGE2: 0.5714\n",
      "  ROUGEL: 0.7500\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation import RetrievalMetrics, GenerationMetrics\n",
    "\n",
    "# Retrieval evaluation\n",
    "retrieval = RetrievalMetrics(k_values=[1, 3, 5])\n",
    "\n",
    "retrieved = [\"doc1\", \"doc3\", \"doc5\", \"doc2\", \"doc4\"]\n",
    "relevant = [\"doc1\", \"doc2\"]\n",
    "\n",
    "metrics = retrieval.evaluate(retrieved, relevant)\n",
    "\n",
    "print(\"Retrieval Metrics:\")\n",
    "for name, result in metrics.items():\n",
    "    print(f\"  {result}\")\n",
    "\n",
    "# Generation evaluation\n",
    "gen_metrics = GenerationMetrics()\n",
    "\n",
    "prediction = \"Machine learning enables computers to learn from data.\"\n",
    "reference = \"Machine learning allows computers to learn from examples.\"\n",
    "\n",
    "rouge_scores = gen_metrics.rouge(prediction, reference)\n",
    "print(\"\\nGeneration Metrics:\")\n",
    "for name, result in rouge_scores.items():\n",
    "    print(f\"  {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hallucination Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grounded answer:\n",
      "  Hallucinated: True\n",
      "  Overlap ratio: 11.11%\n",
      "\n",
      "Hallucinated answer:\n",
      "  Hallucinated: True\n",
      "  Overlap ratio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation import HallucinationDetector\n",
    "\n",
    "detector = HallucinationDetector()\n",
    "\n",
    "sources = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning uses neural networks with multiple layers.\"\n",
    "]\n",
    "\n",
    "grounded = \"Machine learning is part of AI and uses data to learn.\"\n",
    "hallucinated = \"Machine learning was invented in 1850 by Charles Darwin.\"\n",
    "\n",
    "print(\"Grounded answer:\")\n",
    "result = detector.detect_ngram_overlap(grounded, sources)\n",
    "print(f\"  Hallucinated: {result.is_hallucinated}\")\n",
    "print(f\"  Overlap ratio: {result.details['overlap_ratio']:.2%}\")\n",
    "\n",
    "print(\"\\nHallucinated answer:\")\n",
    "result = detector.detect_ngram_overlap(hallucinated, sources)\n",
    "print(f\"  Hallucinated: {result.is_hallucinated}\")\n",
    "print(f\"  Overlap ratio: {result.details['overlap_ratio']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:01:47 | \u001b[32mINFO\u001b[0m | ExperimentTracker | Started run: 20260207_160147_451012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:ExperimentTracker:Started run: 20260207_160147_451012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-07 16:01:47 | \u001b[32mINFO\u001b[0m | ExperimentTracker | Ended run with status: FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:ExperimentTracker:Ended run with status: FINISHED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged 1 runs\n",
      "Run ID: 20260207_160147_451012\n",
      "Metrics: {'ndcg@5': 0.78, 'mrr': 0.82, 'latency_p50': 45.0}\n"
     ]
    }
   ],
   "source": [
    "from src.mlops import ExperimentTracker\n",
    "\n",
    "# Initialize without MLflow for demo\n",
    "tracker = ExperimentTracker(\n",
    "    experiment_name=\"demo_experiment\",\n",
    "    use_mlflow=False\n",
    ")\n",
    "\n",
    "# Start run\n",
    "run_id = tracker.start_run(run_name=\"demo_run\")\n",
    "\n",
    "# Log parameters\n",
    "tracker.log_params({\n",
    "    \"model\": \"all-mpnet-base-v2\",\n",
    "    \"chunk_size\": 500,\n",
    "    \"top_k\": 5\n",
    "})\n",
    "\n",
    "# Log metrics\n",
    "tracker.log_metrics({\n",
    "    \"ndcg@5\": 0.78,\n",
    "    \"mrr\": 0.82,\n",
    "    \"latency_p50\": 45.0\n",
    "})\n",
    "\n",
    "# End run\n",
    "tracker.end_run()\n",
    "\n",
    "# List runs\n",
    "runs = tracker.list_runs()\n",
    "print(f\"Logged {len(runs)} runs\")\n",
    "print(f\"Run ID: {runs[-1].run_id}\")\n",
    "print(f\"Metrics: {runs[-1].metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Configuration & Logging** - Centralized settings management\n",
    "2. **Document Processing** - Text chunking with overlap\n",
    "3. **Embeddings** - Vector generation and similarity\n",
    "4. **Vector Search** - FAISS-based retrieval\n",
    "5. **Evaluation** - Retrieval and generation metrics\n",
    "6. **Hallucination Detection** - N-gram overlap method\n",
    "7. **Experiment Tracking** - MLflow-compatible logging\n",
    "\n",
    "For full RAG pipeline usage, see the CLI: `python -m src.main --help`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG System (venv)",
   "language": "python",
   "name": "rag-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
